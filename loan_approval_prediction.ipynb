{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd  \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "#to draw the plots immediately after the current cell\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads a locally stored CSV file and returns a Pandas DataFrame\n",
    "trainData = pd.read_csv(\"dataset/train_u6lujuX_CVtuZ9i.csv\") \n",
    "\n",
    "#Returns the first 5(default) lines of the DataFrame\n",
    "trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns a tuple with the dimensions of the DataFrame\n",
    "trainData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outputs a general descriptive statistics of the DataFrame\n",
    "#By default only outputs numerical series\n",
    "#include='all' parameter for all numerical and object type series\n",
    "trainData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outputs a general summary of the DataType including the index datatypes, non-null values and memory usage\n",
    "trainData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checks whether each entry is a null of non-null value and returns bool True or False respectively\n",
    "#DataFrame.sum() counts the number of True instances\n",
    "trainData.isnull().sum()\n",
    "\n",
    "#Alternate method\n",
    "#trainData.isnull()[trainData.isnull()==True].count(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing specified columns from the DataFrame\n",
    "#axis=1 means dropping from columns and axis=0(default) means dropping from index\n",
    "trainData.drop([\"Loan_ID\",\"Dependents\"], axis=1, inplace=True)\n",
    "\n",
    "#ignore\n",
    "#trainData.drop(0, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dealing with null values (categorical)\n",
    "cols = trainData[[\"Gender\", \"Married\", \"Self_Employed\"]]\n",
    "\n",
    "#Replacing null values for each categorical series with the mode value\n",
    "#By default mode() ignores null values in calculation of mode\n",
    "for i in cols:\n",
    "    trainData[i].fillna(trainData[i].mode().iloc[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dealing with null values (numerical)\n",
    "n_cols = trainData[[\"LoanAmount\", \"Loan_Amount_Term\", \"Credit_History\"]] \n",
    "for i in n_cols: \n",
    "    trainData[i].fillna(trainData[i].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainData.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternate method to replace null values\n",
    "\n",
    "#values={\n",
    "#    \"Gender\":trainData[\"Gender\"].mode().iloc[0],\n",
    "#    \"Married\":trainData[\"Married\"].mode().iloc[0],\n",
    "#    \"Self_Employed\":trainData[\"Self_Employed\"].mode().iloc[0],\n",
    "#    \"LoanAmount\":trainData[\"LoanAmount\"].mean(),\n",
    "#    \"Loan_Amount_Term\":trainData[\"Loan_Amount_Term\"].mean(),\n",
    "#    \"Credit_History\":trainData[\"Credit_History\"].mean()\n",
    "#}\n",
    "\n",
    "#trainData.(value=values, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization\n",
    "#Defining a function to draw graph of loan status w.r.t. a specified column\n",
    "def bar_chart(col):\n",
    "    #Counting number of approved loans w.r.t. the specific column\n",
    "    Approved = trainData[trainData[\"Loan_Status\"]==\"Y\"][col].value_counts()\n",
    "\n",
    "    #Counting number of disapproved loans w.r.t. the specific column\n",
    "    Disapproved = trainData[trainData[\"Loan_Status\"]==\"N\"][col].value_counts()\n",
    "\n",
    "    df1 = pd.DataFrame([Approved, Disapproved]) \n",
    "    #print(df1)\n",
    "    df1.index = [\"Approved\", \"Disapproved\"]\n",
    "    #print(df1)\n",
    "    df1.plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart(\"Gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting categorical values to Integers\n",
    "from sklearn.preprocessing import OrdinalEncoder \n",
    "\n",
    "#OrdinalEncoder converts a categorical value to a integral value(default dtype=numpy.float64) according to alphabetical order(e.g. Female --> 0 and Male --> 1)\n",
    "ordinalEncoder = OrdinalEncoder(dtype=np.int64)\n",
    "\n",
    "#OrdinalEncoder().fit_transform() first fits the values and transforms it into the same data\n",
    "trainData[[\"Gender\",'Married','Education','Self_Employed','Property_Area','Loan_Status']] = ordinalEncoder.fit_transform(trainData[[\"Gender\",'Married','Education','Self_Employed','Property_Area','Loan_Status']])\n",
    "\n",
    "#Alternate\n",
    "#ord_enc.fit(trainData[[\"Gender\",'Married','Education','Self_Employed','Property_Area','Loan_Status']])\n",
    "#trainData[[\"Gender\",'Married','Education','Self_Employed','Property_Area','Loan_Status']] = ord_enc.transform(trainData[[\"Gender\",'Married','Education','Self_Employed','Property_Area','Loan_Status']])\n",
    "\n",
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X = trainData.drop(\"Loan_Status\", axis=1) \n",
    "y = trainData[\"Loan_Status\"]\n",
    "\n",
    "#Splits arrays into random train and test subsets\n",
    "#test_size, if float, is the fraction of the dataset to include in the test split, if int, is the absolute number of test samples\n",
    "#random_state parameter to produce reproducible results(can be any int)\n",
    "XTrain, XTest = train_test_split(X,test_size=0.2, random_state=42, stratify=X[\"Gender\"])\n",
    "yTrain, yTest = train_test_split(y,test_size=0.2, random_state=42, stratify=X[\"Gender\"])\n",
    "\n",
    "#Alternate\n",
    "#XTrain, XTest, yTrain, yTest = train_test_split(X,y,test_size=0.2, random_state=2) \n",
    "\n",
    "print(XTrain.shape) \n",
    "print(yTrain.shape)\n",
    "print(XTest.shape) \n",
    "print(yTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gfc = GaussianNB()\n",
    "gfc.fit(XTrain, yTrain)\n",
    "pred1 = gfc.predict(XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "def loss(y_true, y_pred): \n",
    "    pre = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # f1 = HM(precision, recall)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    print(pre) \n",
    "    print(rec)\n",
    "    print(acc)\n",
    "    print(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss(yTest, pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "# C : measure of how much error is allowed\n",
    "# gamma : for rbf kernel; in layman terms, measure of curvature of curve \n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf']} \n",
    "\n",
    "# default scorer for classification is accuracy\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose =3) \n",
    "grid.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svc = SVC(C= 0.1, gamma= 1, kernel= 'rbf')  \n",
    "#svc = SVC(gamma='auto')\n",
    "svc.fit(XTrain, yTrain)\n",
    "pred2 = svc.predict(XTest) \n",
    "\n",
    "loss(yTest,pred2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
